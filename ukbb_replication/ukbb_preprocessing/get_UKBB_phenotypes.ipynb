{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T20:40:28.008075Z",
     "start_time": "2020-02-11T12:40:23.962086-08:00"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import urllib.request\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_continuous_traits = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_data_dir = \"/u/project/sriram/ukbiobank/33127/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_files = glob.glob(os.path.join(pheno_data_dir, \"ukb*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_file = pheno_files[0]\n",
    "#html_file = os.path.join(pheno_data_dir, os.path.splitext(os.path.basename(phenotype_file))[0] + \".html\")\n",
    "html_file = os.path.join(pheno_data_dir, (os.path.splitext(os.path.basename(phenotype_file))[0]).split(\".\")[0] + \".html\")\n",
    "\n",
    "ukbb_phenotype_code_url = \"http://biobank.ndph.ox.ac.uk/showcase/coding.cgi?id={}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Phenotype file: {}\".format(phenotype_file))\n",
    "print(\"HTML file: {}\".format(html_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in HTML file with phenotype mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = \"\"\n",
    "encoding = None\n",
    "try:\n",
    "    with open(html_file, \"r\", encoding=encoding) as hf:\n",
    "        html_text = hf.read()\n",
    "except UnicodeDecodeError:\n",
    "    encoding = \"latin-1\"\n",
    "    with open(html_file, \"r\", encoding=encoding) as hf:\n",
    "        html_text = hf.read()\n",
    "print(\"final encoding: {}\".format(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(html_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pandas data frame from html table\n",
    "\n",
    "The .html file has the mapping from phenotype -> .csv column index, so we can search this .html file for specific phenotypes of interest, figure out which column indices we need, and then use these indices to index the large .csv file which contains the data per patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "html_df = pd.read_html(html_text, encoding=encoding)[1]\n",
    "print(\"elapsed time: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column that contains codes for mapping categorical variable integers to strings\n",
    "def find_codes(description):\n",
    "    term1 = \"Uses data-coding\"\n",
    "    term2 = \"comprises\"\n",
    "    if term1 in description:\n",
    "        code = description.split(term1)[1].strip()\n",
    "        if term2 in description: \n",
    "            code = code.split(term2)[0].strip()\n",
    "        return code\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "html_df[\"Data_Coding\"] = html_df[\"Description\"].apply(find_codes)\n",
    "html_df[\"Data_Coding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove code from phenotype description col\n",
    "def remove_codes(description):\n",
    "    term = \"Uses data-coding\"\n",
    "    if term in description:\n",
    "        return description.split(term)[0].strip()\n",
    "    else:\n",
    "        return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_df[\"Description\"] = html_df[\"Description\"].apply(remove_codes)\n",
    "html_df[\"Description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for rows matching a particular term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = [\n",
    "    \"BMI\",\n",
    "    \"Standing height\",\n",
    "    \"Weight\",\n",
    "    \"Body fat percentage\",\n",
    "    \"Pulse rate\",\n",
    "    \"Systolic blood pressure\",\n",
    "    \"Diastolic blood pressure\",\n",
    "    \"Vascular/heart problems diagnosed by doctor\",\n",
    "    \"Age stroke diagnosed\",\n",
    "    \"Age angina diagnosed\",\n",
    "    \"Age heart attack diagnosed\",\n",
    "    \"Age high blood pressure diagnosed\",\n",
    "    \"Diabetes diagnosed by doctor\",\n",
    "    \"Medication for cholesterol, blood pressure or\",\n",
    "    \"Frequency of drinking alcohol\",\n",
    "    \"Alcohol intake frequency\",\n",
    "    \"Smoking status\",\n",
    "    \"Qualifications\",\n",
    "    \"Job code\",\n",
    "    \"Average total household income before tax\",\n",
    "    \"Townsend\",\n",
    "    \"Number of live births\",\n",
    "    \"Age completed full time education\",\n",
    "    \"Age when attended assessment centre\",\n",
    "    \"UK Biobank assessment centre\",\n",
    "    \"Sex\",\n",
    "    \"Genetic sex\",\n",
    "    \"Genotype measurement batch\",\n",
    "    \"Genotype measurement plate\",\n",
    "    \"Genotype measurement well\",\n",
    "    \"Genetic kinship to other participants\",\n",
    "    \"Date of attending assessment centre\",\n",
    "    \"Ethnic background\",\n",
    "    \"Genetic principal components\",\n",
    "    \"Outliers for heterozygosity or missing rate\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_use = []\n",
    "missing_features = []\n",
    "print(\"Querying for {} terms\".format(len(search_terms)))\n",
    "for term in search_terms:\n",
    "    # look for all rows that contain search term\n",
    "    rows = html_df[html_df[\"Description\"].str.contains(term)].sort_values(\"Count\", ascending=False)\n",
    "    # if we don't find any, add to list of missing features\n",
    "    if rows.shape[0] == 0:\n",
    "        missing_features.append(term)\n",
    "    # otherwise add these rows for use\n",
    "    else:\n",
    "        rows_to_use.append(rows)\n",
    "        \n",
    "print(\"Found {} rows\".format(len(rows_to_use)))\n",
    "print(\"Could not find {} terms\".format(len(missing_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing terms:\\n\")\n",
    "[print(f) for f in missing_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if looking to dump all continuous traits, set this flag to true\n",
    "if add_continuous_traits:\n",
    "    rows = html_df[html_df[\"Type\"] == \"Continuous\"]\n",
    "    print(\"Adding {} rows for continuous traits\".format(rows.shape[0]))\n",
    "    rows_to_use.append(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chd = html_df[html_df[\"Description\"].str.contains(\"Alcohol\")].sort_values(\"Count\", ascending=False)\n",
    "chd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all rows to use into single DF\n",
    "relevant_rows = pd.concat(rows_to_use)\n",
    "relevant_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in phenotype file\n",
    "\n",
    "The phenotype file is large, so we can save time/memory by only reading the columns we specifically need. We can use the phenotype -> column index mapping from the .html file to only grab specific columns from the .csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only relevant columns \n",
    "relevant_cols = relevant_rows[\"Column\"]\n",
    "relevant_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add in column 0 since it contains the EID\n",
    "start_time = time.time()\n",
    "pheno_df = pd.read_csv(phenotype_file, sep=\",\", header=0, usecols=[0]+list(relevant_cols))\n",
    "print(\"Loading took {} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map categorical phenotype integers to strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in pheno_df.columns.values:\n",
    "    pheno_row = html_df[html_df[\"UDI\"] == col]\n",
    "    \n",
    "    # if we have a code in the Data_Coding column, go get mapping\n",
    "    code = pheno_row[\"Data_Coding\"].iloc[0]\n",
    "    if code is not None:\n",
    "        # get contents of UKBB webpage, and include code in URL\n",
    "        \n",
    "        try:\n",
    "            contents = urllib.request.urlopen(ukbb_phenotype_code_url.format(code)).read()\n",
    "            try:\n",
    "                # convert returned HTML into pandas data frame\n",
    "                mapping_df = pd.read_html(contents)[1]\n",
    "                # set Coding column as index\n",
    "                mapping_df.set_index(\"Coding\", inplace=True)\n",
    "                print(mapping_df)\n",
    "                # create a mapping from integer codes to string codes\n",
    "                mapping_dict = mapping_df.to_dict(orient=\"dict\")\n",
    "                # replace integer coding with string coding\n",
    "                pheno_df[col].replace(mapping_dict[\"Meaning\"], inplace=True)\n",
    "\n",
    "            # found to happen when there is a hierarchical tree-structured dict mapping which \n",
    "            # requires more work...\n",
    "            except IndexError as e:\n",
    "                pass\n",
    "        except:\n",
    "            print(\"ERROR: cannot make URL Request\")\n",
    "            print(\"Row:\", pheno_row)\n",
    "            print(\"Col:\", col)\n",
    "            print(\"Code:\", code)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename columns using phenotype description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to phenotype description\n",
    "column_mapping = {}\n",
    "for col in pheno_df.columns.values:\n",
    "    column_mapping[col] = html_df[html_df[\"UDI\"] == col][\"Description\"].values[0] + \"_\" + col\n",
    "\n",
    "column_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df.to_csv(\"/u/scratch/b/blhill/UKBB_phenotypes_{}.tsv\".format(os.path.splitext(os.path.basename(phenotype_file))[0]), \n",
    "                sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df = pd.read_csv(\"UKBB_phenotypes_{}.tsv\".format(os.path.splitext(os.path.basename(phenotype_file))[0]), \n",
    "                       sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in pheno_df.columns.values:\n",
    "    print(c, pheno_df[c].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the two .tsv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df1 = pd.read_csv(\"/u/scratch/b/blhill/UKBB_phenotypes_ukb39967.enc_ukb.converted2.tsv\", header=0, sep=\"\\t\")\n",
    "pheno_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df2 = pd.read_csv(\"/u/scratch/b/blhill/UKBB_phenotypes_ukb21970.tsv\", header=0, sep=\"\\t\")\n",
    "pheno_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_overlapping_cols = list(pheno_df2.columns.values[~pheno_df2.columns.isin(pheno_df1.columns.values)])\n",
    "non_overlapping_cols = non_overlapping_cols + list([\"Encoded anonymised participant ID_eid\"])\n",
    "print(\"Found {} non-overlapping columns\".format(len(non_overlapping_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(pheno_df1, pheno_df2[non_overlapping_cols], how=\"left\", on=\"Encoded anonymised participant ID_eid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"merged dataframe shape:\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"/u/scratch/b/blhill/UKBB_phenotypes_merged.tsv\", header=True, index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
